{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Let's play real tennis\n",
    "\n",
    "#### 3.1. Importing modules and adding some jupyter-notebook magic\n",
    "\n",
    "##### 3.1.1. Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. Jupyter-notebook magic\n",
    "\n",
    "The magic is here - let matplotlib in the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Parameters\n",
    "\n",
    "##### 3.2.1. CONSTANTS\n",
    "\n",
    "The following CONSTANTS influece the training process. Play with them if you're up to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\t\t# Size of the replay buffer.\n",
    "BUFFER_SIZE = int(1e5)\t# Size of the mini batches.\n",
    "GAMMA = 0.99\t\t\t# Discount factor, Gamma.\n",
    "L2_WEIGHT_DECAY = 0\t\t# L2 weight decay.\n",
    "LR_ACTOR = 2e-4\t\t\t# Learning rate of the actor.\n",
    "LR_CRITIC = 1e-3\t\t# Learning rate of the critic.\n",
    "RANDOM_SEED = 12345\t\t# An integer to fire up random generators.\n",
    "TAU = 1e-3\t\t\t\t# Parameter Tau serves to set soft update of target parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2. Globally significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Training on {}.'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Classes\n",
    "\n",
    "##### 3.3.1. Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents an Actor (Policy) Model. It inherts from PyTorch NN Module.\n",
    "    __init__(), forward() and reset_parameters() are overwritten only.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=256, fc2_units=128):\n",
    "        \"\"\"\n",
    "        Initializes the class.\n",
    "        ----------------------\n",
    "        @Params:\tstate_size\t(int)\tCount of state's dimensions.\n",
    "                    action_size\t(int)\tCount of action's dimensions.\n",
    "                    seed\t\t(int)\tRendom seed.\n",
    "                    fc1_size\t(int)\t[optional] Count of nodes in the 1st fully connected layer.\n",
    "                    fc2_size\t(int)\t[optional] Count of nodes in the 2nd fully connected layer.\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Fordwards the input (state) through the whole network and returns the network's output.\n",
    "        ---------------------------------------------------------------------------------------\n",
    "        @Params:\tstate\t(torch.Tensor)\tInput data (state).\n",
    "        @Return:\t(torch.Tensor)\t\t\tThe output of the network (action).\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Resets weights.\n",
    "        ---------------\n",
    "        \"\"\"\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-0.003, 0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2. Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \"\"\"\n",
    "    This class represents an agent who inteacts with the environment and can learn from it.\n",
    "    This class doesn't really have any superclass aside of object which is the top most superclass usually.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, state_size, action_size, num_agents, random_seed):\n",
    "        \"\"\"\n",
    "        Initializes the class.\n",
    "        ----------------------\n",
    "        @Params:\tstate_size\t\t(int)\tCount of state's dimensions.\n",
    "                    action_size\t\t(int)\tCount of action's dimensions.\n",
    "                    num_agents\t\t(int)\tNumber of agents.\n",
    "                    seed\t\t\t(int)\tRendom seed.\n",
    "        \"\"\"\n",
    "        global BATCH_SIZE\n",
    "        global BUFFER_SIZE\n",
    "        global EPSILON\n",
    "        global LR_ACTOR\n",
    "        global LR_CRITIC\n",
    "        global L2_WEIGHT_DECAY\n",
    "        \n",
    "        global davice\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.num_agents = num_agents\n",
    "        \n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=LR_CRITIC, weight_decay=L2_WEIGHT_DECAY)\n",
    "\n",
    "        self.noise = Noise((num_agents, action_size), random_seed)\n",
    "\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
    "\n",
    "\n",
    "\n",
    "    def act(self, states, act_noisy=True):\n",
    "        \"\"\"\n",
    "        Performs an action from the given state and adds noise actions if needed.\n",
    "        -------------------------------------------------------------------------\n",
    "        @Params:\tstates\t\t(array like)\tCurrent state.\n",
    "                    act_noisy\t(boolean)\t\tWhether to add noise or not.\n",
    "        \"\"\"\n",
    "        global device\n",
    "        \n",
    "        states = torch.from_numpy(states).float().to(device)\n",
    "        actions = np.zeros((self.num_agents, self.action_size))\n",
    "        \n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            for agent_num, state in enumerate(states):\n",
    "                action = self.actor_local(state).cpu().data.numpy()\n",
    "                actions[agent_num, :] = action\n",
    "        self.actor_local.train()\n",
    "        \n",
    "        if act_noisy:\n",
    "            actions += self.noise.sample()\n",
    "        \n",
    "        # Keep valid action samples only.\n",
    "        return np.clip(actions, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"\n",
    "        Performs experience based update of parameters.\n",
    "        -----------------------------------------------\n",
    "        @Params:\texperience\t(tuple)\tExperiences to work with.\n",
    "                    gamma\t\t(float)\tThe value of the discount factor.\n",
    "        \"\"\"\n",
    "        global TAU\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        # Those lines below serve to calculate targets and Q-values.\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        \n",
    "        # Critic network is updated here.\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        # Finally actor netowrk is updated too with the help of the critic network.\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # Both actor and critic network need a soft update.\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the used noise.\n",
    "        ----------------------\n",
    "        \"\"\"\n",
    "        self.noise.reset()\n",
    "\n",
    "\n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"\n",
    "        Performs soft update on model parameters.\n",
    "        -----------------------------------------\n",
    "        @Params:\tlocal_model\t\t(nn.Module)\tModel to copy weights from.\n",
    "                    target_model\t(nn.Module)\tModel to copy weights to.\n",
    "                    tau\t\t\t\t(float)\t\tParameter of interpolation.\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Takes a step in the action-space and calls learning if needed.\n",
    "        --------------------------------------------------------------\n",
    "        @Params:\tstate\t\t(float)\tCurrent state.\n",
    "                    action\t\t(float)\tTaken action.\n",
    "                    reward\t\t(float)\tReceived reward.\n",
    "                    next_state\t(float)\tNext state (resulting state).\n",
    "                    done\t\t(float)\tWhether it's finished or not.\n",
    "        \"\"\"\n",
    "        global BATCH_SIZE\n",
    "        global GAMMA\n",
    "        \n",
    "        for i in range(self.num_agents):\n",
    "            self.memory.add(state[i, :], action[i, :], reward[i], next_state[i, :], done[i])\n",
    "\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3. Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents a Critic (Value) Model. It inherts from PyTorch NN Module.\n",
    "    __init__(), forward() and reset_parameters() are overwritten only.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=256, fc2_units=128):\n",
    "        \"\"\"\n",
    "        Initializes the class.\n",
    "        ----------------------\n",
    "        @Params:\tstate_size\t(int)\tCount of state's dimensions.\n",
    "                    action_size\t(int)\tCount of action's dimensions.\n",
    "                    seed\t\t(int)\tRendom seed.\n",
    "                    fc1_size\t(int)\t[optional] Count of nodes in the 1st fully connected layer.\n",
    "                    fc2_size\t(int)\t[optional] Count of nodes in the 2nd fully connected layer.\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        self.fcs1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units + action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        Fordwards the input (state) through the whole network and returns the network's output.\n",
    "        ---------------------------------------------------------------------------------------\n",
    "        @Params:\tstate\t(torch.Tensor)\tStates.\n",
    "                    action\t(torch.Tensor)\tActions.\n",
    "        @Return:\t(torch.Tensor)\t\t\tQ-targets.\n",
    "        \"\"\"\n",
    "        xs = F.relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Resets weights.\n",
    "        ---------------\n",
    "        \"\"\"\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-0.003, 0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4. Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise(object):\n",
    "    \"\"\"\n",
    "    This class creates noise to the training process. It implements the Ornstein-Uhlenbeck process.\n",
    "    This class doesn't really have any superclass aside of object which is the top most superclass usually.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, size, seed, mu=0.0, theta=0.15, sigma=0.2):\n",
    "        \"\"\"\n",
    "        Initializes the class.\n",
    "        ----------------------\n",
    "        @Params:\tsize\t(int)\tThe size of the noise.\n",
    "                    seed\t(int)\tRendom seed.\n",
    "                    mu\t\t(float)\t[optional] Base value of mu.\n",
    "                    theta\t(float)\t[optional] Value of theta.\n",
    "                    sigma\t(float)\t[optional] Value of sigma.\n",
    "        \"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.size = size\n",
    "        \n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the class's state to the default.\n",
    "        ----------------------------------------\n",
    "        \"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Samples random noise from state and updates the state.\n",
    "        ------------------------------------------------------\n",
    "        @Return:\t(np.ndarray)\tNoise.\n",
    "        \"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.standard_normal(self.size)\n",
    "        self.state = x + dx\n",
    "        \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.5. Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \"\"\"\n",
    "    This class represents the experience of the agent.\n",
    "    This class doesn't really have any superclass aside of object which is the top most superclass usually.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"\n",
    "        Initializes the class.\n",
    "        ----------------------\n",
    "        @Params:\taction_size\t(int)\tCount of action's dimensions.\n",
    "                    buffer_size\t(int)\tSize of the actual buffer.\n",
    "                    batch_size\t(int)\tSize of training batches.\n",
    "                    seed\t\t(int)\tRendom seed.\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        \n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Adds a new experience to the memory.\n",
    "        ------------------------------------\n",
    "        @Params:\tstate\t\t(float)\tCurrent state.\n",
    "                    action\t\t(float)\tTaken action.\n",
    "                    reward\t\t(float)\tReceived reward.\n",
    "                    next_state\t(float)\tNext state (resulting state).\n",
    "                    done\t\t(float)\tWhether it's finished or not.\n",
    "        \"\"\"\n",
    "        newexperience = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(newexperience)\n",
    "\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Samples random batches from the memory.\n",
    "        ---------------------------------------\n",
    "        @Return:\t(tuple)\tBatch\n",
    "        \"\"\"\n",
    "        global device\n",
    "\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the size of the buffer's memory and ensures the compatibility with the len() function.\n",
    "        \"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawresults(scores, save_to=None):\n",
    "    \"\"\"\n",
    "    Draws and saves scores.\n",
    "    -----------------------\n",
    "    @Params:\tscores\t(list like)\tScores to display.\n",
    "                save_to\t(string)\t[optional] File name to save figure if given.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[10, 5])\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    scores_rolling = pd.Series(scores).rolling(100).mean()\n",
    "    ax.plot(scores)\n",
    "    ax.plot(scores_rolling, c=\"green\", linewidth=3)\n",
    "    ax.set_xlabel(\"Episodes\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.grid(which=\"major\")\n",
    "    ax.axhline(0.5, c=\"red\", linewidth=3)\n",
    "    ax.legend([\"Scores of episodes\", \"Average of last 100 episodes\", \"Target score=0.5\"])\n",
    "    \n",
    "    if save_to != None:\n",
    "        fig.savefig(save_to)\n",
    "\n",
    "\n",
    "\n",
    "def hidden_init(layer):\n",
    "    \"\"\"\n",
    "    Initializes a layer with the process of: 1.0 / sqrt(layer)\n",
    "    ----------------------------------------------------------\n",
    "    @Params:\tlayer\t(torch.Tensor)\tLayer to initialize.\n",
    "    @Return:\t(torch.Tensor)\t\t\tThe initialized layer.\n",
    "    \"\"\"\n",
    "    layer_n = layer.weight.data.size()[0]\n",
    "    lim = 1.0 / np.sqrt(layer_n)\n",
    "\n",
    "    return (-lim, lim)\n",
    "\n",
    "\n",
    "\n",
    "def train(episodes_count=50000, print_at_every=100):\n",
    "    \"\"\"\n",
    "    Performs the training\n",
    "    ---------------------\n",
    "    @Params:\tepisode_count\t(int)\t[optional] Count of episodes.\n",
    "                print_at_every\t(int)\t[optional] Length of the interval of episodes to log like print the result.\n",
    "    @Return:\t(list of ints)\t\t\tScores\n",
    "    \"\"\"\n",
    "    global agent\n",
    "    global brain_name\n",
    "    global env\n",
    "    global num_agents\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    all_scores = []\n",
    "    \n",
    "    # The value of episode is more human like this way since it changes from 1...x instead of 0...x-1 and\n",
    "    # shows the number of the actual episode just like humans understand more.\n",
    "    for episode in range(1, episodes_count+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agents)\n",
    "        \n",
    "        # The line below doesn't look like a cite from the book \"Best practices in loops\" but this time\n",
    "        # it'll serve just fine since someone should win anyway.\n",
    "        while True:\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            scores += np.array(rewards)\n",
    "            states = next_states            \n",
    "\n",
    "            # Break out from infinity if anyone finished this game.\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        scores_deque.append(np.amax(scores))\n",
    "        all_scores.append(np.amax(scores))\n",
    "        \n",
    "        print('\\rEpisode {:4d}:\\tAverage of last 100 scores is {:.4f}.\\tScore of agent_1:{:.4f}.\\tScore of agent_2:{:.4f}.  '\n",
    "              .format(episode, np.mean(scores_deque), scores[0], scores[1]), end='')\n",
    "                \n",
    "        if episode % print_at_every == 0:\n",
    "            print('\\rEpisode {:4d}:\\tAverage of last 100 scores is {:.4f}.\\tScore of agent_1:{:.4f}.\\tScore of agent_2:{:.4f}.  '\n",
    "                  .format(episode, np.mean(scores_deque), scores[0], scores[1]))\n",
    "                        \n",
    "        if np.mean(scores_deque) >= 0.5:\n",
    "            print('\\n\\nTraining finished.')\n",
    "            print('\\rEpisode {:4d}:\\tAverage of last 100 scores is {:.4f}.\\tScore of agent_1:{:.4f}.\\tScore of agent_2:{:.4f}.  '\n",
    "                  .format(episode, np.mean(scores_deque), scores[0], scores[1]))\n",
    "            torch.save(agent.actor_local.state_dict(), \"tennis_actor.pth\")\n",
    "            torch.save(agent.critic_local.state_dict(), \"tennis_critic.pth\")\n",
    "            break\n",
    "\n",
    "    return all_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Let's touch those arms\n",
    "\n",
    "##### 3.5.1. Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.2. Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  100:\tAverage of last 100 scores is 0.0020.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode  200:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:-0.0100.\tScore of agent_2:0.0000.  \n",
      "Episode  300:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode  400:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:-0.0100.\tScore of agent_2:0.0000.  \n",
      "Episode  500:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode  600:\tAverage of last 100 scores is 0.0078.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode  700:\tAverage of last 100 scores is 0.0155.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode  800:\tAverage of last 100 scores is 0.0138.\tScore of agent_1:-0.0100.\tScore of agent_2:0.0000.  \n",
      "Episode  900:\tAverage of last 100 scores is 0.0010.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1000:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:-0.0100.\tScore of agent_2:0.0000.  \n",
      "Episode 1100:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1200:\tAverage of last 100 scores is 0.0000.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1300:\tAverage of last 100 scores is 0.0030.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1400:\tAverage of last 100 scores is 0.0010.\tScore of agent_1:0.0000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1500:\tAverage of last 100 scores is 0.0241.\tScore of agent_1:0.1000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1600:\tAverage of last 100 scores is 0.0469.\tScore of agent_1:0.1000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1700:\tAverage of last 100 scores is 0.0784.\tScore of agent_1:-0.0100.\tScore of agent_2:0.1000.  \n",
      "Episode 1800:\tAverage of last 100 scores is 0.0838.\tScore of agent_1:0.1000.\tScore of agent_2:-0.0100.  \n",
      "Episode 1900:\tAverage of last 100 scores is 0.0960.\tScore of agent_1:0.1000.\tScore of agent_2:0.0900.   \n",
      "Episode 2000:\tAverage of last 100 scores is 0.0828.\tScore of agent_1:0.1000.\tScore of agent_2:-0.0100.  \n",
      "Episode 2100:\tAverage of last 100 scores is 0.1405.\tScore of agent_1:0.6000.\tScore of agent_2:0.4900.   \n",
      "Episode 2200:\tAverage of last 100 scores is 0.3887.\tScore of agent_1:0.6900.\tScore of agent_2:0.8000.   \n",
      "Episode 2300:\tAverage of last 100 scores is 0.2535.\tScore of agent_1:0.0900.\tScore of agent_2:0.2000.   \n",
      "Episode 2400:\tAverage of last 100 scores is 0.2792.\tScore of agent_1:-0.0100.\tScore of agent_2:0.0000.  \n",
      "Episode 2500:\tAverage of last 100 scores is 0.4277.\tScore of agent_1:-0.0100.\tScore of agent_2:0.0000.  \n",
      "Episode 2600:\tAverage of last 100 scores is 0.4141.\tScore of agent_1:0.7000.\tScore of agent_2:0.6900.   \n",
      "Episode 2632:\tAverage of last 100 scores is 0.5074.\tScore of agent_1:0.9000.\tScore of agent_2:0.7900.   \n",
      "\n",
      "Training finished.\n",
      "Episode 2632:\tAverage of last 100 scores is 0.5074.\tScore of agent_1:0.9000.\tScore of agent_2:0.7900.  \n"
     ]
    }
   ],
   "source": [
    "scores = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.3. See the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "drawresults(scores, './tennis_scores.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6. Test the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if a well trained agent plays against itself, the mean of scores is 0.0950.\n"
     ]
    }
   ],
   "source": [
    "# This time I'll use standard random seed 0 to ignite random things again.\n",
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=0)\n",
    "\n",
    "agent.actor_local.load_state_dict(torch.load(\"tennis_actor.pth\"))\n",
    "agent.critic_local.load_state_dict(torch.load(\"tennis_critic.pth\"))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "scores = np.zeros(num_agents)\n",
    "\n",
    "# Let's face the potential infinity once more.\n",
    "while True:\n",
    "    actions = agent.act(states)\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    scores += env_info.rewards\n",
    "    states = next_states\n",
    "    \n",
    "    # Break out from infinity if anyone finished this game.\n",
    "    if np.any(dones):\n",
    "        break\n",
    "\n",
    "print('if a well trained agent plays against itself, the mean of scores is {:.4f}.'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7. The end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
